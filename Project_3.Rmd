---
title: "Project_3"
author: "Aaron Zelmanov, Muhammad Hafizudeen Mohamad Saman, Nakul Chadha, Kendall Cohen, Michael Geraci"
date: "3/29/2021"
output:
  html_document:
    code_folding: hide
---
## {.tabset}

### Introduction 
```{r setup, include=FALSE}
#knitr::opts_chunk$set(cache=TRUE)
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(GGally)
library(class)
library(caret)
library(gmodels)
library(InformationValue)
library(C50)
library(neuralnet)
library(InformationValue)
library(dplyr)
library(kernlab)

airline_train <- read.csv("train.csv")
airline_test <- read.csv("test.csv")

airline_train_corr <- airline_train

airline_train$X <- NULL
airline_train$id <- NULL
airline_train$Gender <- as.factor(airline_train$Gender)
airline_train$Customer.Type <- as.factor(airline_train$Customer.Type)
airline_train$Type.of.Travel <- as.factor(airline_train$Type.of.Travel)
airline_train$Class <- as.factor(airline_train$Class)
airline_train$satisfaction <- as.numeric(as.factor(airline_train$satisfaction))-1

airline_test$X <- NULL
airline_test$id <- NULL
airline_test$Gender <- as.factor(airline_test$Gender)
airline_test$Customer.Type <- as.factor(airline_test$Customer.Type)
airline_test$Type.of.Travel <- as.factor(airline_test$Type.of.Travel)
airline_test$Class <- as.factor(airline_test$Class)
airline_test$satisfaction <- as.numeric(as.factor(airline_test$satisfaction))-1

airline_train$Arrival.Delay.in.Minutes[is.na(airline_train$Arrival.Delay.in.Minutes)] <- mean(airline_train$Arrival.Delay.in.Minutes, na.rm = TRUE)
airline_test$Arrival.Delay.in.Minutes[is.na(airline_test$Arrival.Delay.in.Minutes)] <- mean(airline_test$Arrival.Delay.in.Minutes, na.rm = TRUE)
```

**Context:** We are working with the airline dataset which contains various demographics and flight information along with the final satisfaction level.  

**Audience:** The results of our models are useful for airlines in order to optimize their flight experience, lead to maximum satisfaction, and determine which passengers will be satisfied. 

**Key Business Objectives:** What factors are predictive of a satisfied or dissatisfied passenger? How can airlines use this information to improve certain aspects of service? How can airlines predict who to invest more in (dissatisfied passengers)? 

```{r}
#Train and Test sets to use 

#airline_train FOR decision tree, regression
#airline_test FOR decision tree, regression
#airline_train_factorized_normalized FOR KNN, ANN
#airline_test_factorized_normalized FOR KNN, ANN

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) #everything 0 to 1
}

airline_train_factorized<- as.data.frame(model.matrix(~.-1, data = airline_train))
airline_train_factorized_normalized <- as.data.frame(lapply(airline_train_factorized[1:ncol(airline_train_factorized)], normalize))
airline_factorizednormalized_trainlabels <- airline_train_factorized_normalized["satisfaction"]

airline_test_factorized<- as.data.frame(model.matrix(~.-1, data = airline_test))
airline_test_factorized_normalized <- as.data.frame(lapply(airline_test_factorized[1:ncol(airline_test_factorized)], normalize))
airline_factorizednormalized_testlabels <- airline_test_factorized_normalized["satisfaction"]
```

### Exploration 

**The goal of this analysis is to identify opportunities for which metrics this airline can improve and how that would affect the overall satisfaction of their customers. We want to look at the elements that are the most and least likely to induce a positive or neutral/negative reaction in a customer. This way, we can identify the elements that the airline needs to improve on and where they need to spend the most amount of their resources (time/money).**
<br />
<br />

**Customer Satisfaction**
```{r}
satisfaction_table <- table(airline_train$satisfaction)
satisfaction_table
prop.table(satisfaction_table)
```

*First, we will look at how many customers are satisfied and neutral/dissatisfied. Right off the bat, we see that more than half of customers are neutral/dissatisfied. Next, we will look at the potential variables that are leading to this through the use of a correlation graph and matrix.*

```{r, warning=FALSE}
#Correlations with satisfaction 
correlations <- as.data.frame(cor(airline_train[sapply(airline_train, function(x) is.numeric(x))])[19,])
correlations %>% ggplot(aes(x=reorder(rownames(correlations), correlations[,1]), y=correlations[,1])) + 
geom_bar(stat = 'identity') + ggtitle("Correlations with Satisfaction") + labs(x="Variables", y="Correlation") + theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 90))
```

*The correlations graph above shows the correlations between variables in the dataset and satisfaction. Online boarding, in-flight entertainment, and seat comfort seem to be the most strongly correlated with satisfaction. This makes sense because these are some of they key features of a good flight. As a note, satisfaction appears as one of the variables and predictably is 100% correlated with itself. Interestingly, some of the negative aspects of a flight aren't highly negatively correlated: delays, inconvenient departure times, etc* 
<br />
<br />

```{r, warning=FALSE}
#Female = 1, Male = 2
airline_train_corr$Gender <- as.integer(airline_train$Gender)
airline_train_corr$Customer.Type <- as.integer(airline_train$Customer.Type)
airline_train_corr$Type.of.Travel <- as.integer(airline_train$Type.of.Travel)
airline_train_corr$Class <- as.integer(airline_train$Class)
airline_train_corr$satisfaction <- as.integer(airline_train$satisfaction)

airline_train_corr$X <- NULL
airline_train_corr$id <- NULL

ggcorr(airline_train_corr, nbreaks = 4, palette = "RdGy", label = TRUE, label_size = 2, hjust = 1, label_color = "white") + ggtitle("Correlations Between all Variables") + theme(plot.title = element_text(hjust = 0.5))
```

*The correlations chart above shows us the correlations between all variables, identifying those with strong, weak, and perhaps no correlations*

<br />
<br />
**Now, let's take a look at the variables that could have a significant effect on our response.**
```{r}
mean_inflight_wifi <- mean(airline_train$Inflight.wifi.service)
mean_departure_arrival <- mean(airline_train$Departure.Arrival.time.convenient)
mean_ease <- mean(airline_train$Ease.of.Online.booking)
mean_gate <- mean(airline_train$Gate.location)
mean_food_drink <- mean(airline_train$Food.and.drink)
mean_online_board <- mean(airline_train$Online.boarding)
mean_seat <- mean(airline_train$Seat.comfort)
mean_inflight_entertain <- mean(airline_train$Inflight.entertainment)
mean_onboard_service <- mean(airline_train$On.board.service)
mean_leg_room <- mean(airline_train$Leg.room.service)
mean_baggage <- mean(airline_train$Baggage.handling)
mean_checkin <- mean(airline_train$Checkin.service)
mean_inflight_service <- mean(airline_train$Inflight.service)
mean_cleanliness <- mean(airline_train$Cleanliness)
mean_df <- data.frame(mean_inflight_wifi, mean_departure_arrival, mean_ease, mean_gate, mean_food_drink, mean_online_board, mean_seat, mean_inflight_entertain, mean_onboard_service, mean_leg_room, mean_baggage, mean_checkin, mean_inflight_service, mean_cleanliness)

colnames(mean_df) <- c("InFlight Wifi Service", "Departure Arrival Time Convenient", "Ease of Online Booking", "Gate Location", "Food & Drink", "Online Boarding", "Seat Comfort", "Inflight Entertainment", "On-board Service", "Leg Room Service", "Baggage Handling", "Check-in Service", "Inflight Service", "Cleanliness")

mean_df
```

*After calculating the mean customer ratings for 14 different variables (services, timing, locations, accessibility, etc), three variables automatically stand out as those that the airline needs to focus on (lowest ratings): Inflight Wifi Service, Ease of Online Booking, and Gate Location. If it could improve on these three, the more likely more customers will be satisfied with their experiences.*
<br />
<br />

**Let's dive deeper into these three variables and see their relationship with satisfaction.**

```{r}
#Inflight Wifi Service vs Satisfaction
ggplot(airline_train,
       aes(x = Inflight.wifi.service,
           fill = factor(satisfaction,
           labels = c("Neutral or Dissatisfied", "Satisfied")))) +
  geom_bar(position = "dodge") + 
  labs(y = "Number Satisfied", x = "Inflight Wifi Service Rating", fill = "Satisfaction", title = "Number Satisfied vs Inflight Wifi Service Rating") + theme(plot.title = element_text(hjust = 0.5))

wifi_satisfaction <- setNames(aggregate(as.numeric(satisfaction) - 1 ~ Inflight.wifi.service, data = airline_train, sum), c("Inflight Wifi Service Rating", "Total Satisfied"))
wifi_satisfaction
```

*The chart above displays the distribution between the Inflight Wifi Service Rating and the corresponding number of people who were satisfied/unsatisfied. As expected, as the rating for inflight wifi service increases, so does the number of people who are satisfied. Interestingly, the number of people who are neutral or dissatisfied is very similar if the rating is 2 or 3, which is in line with the mean inflight wifi service rating as calculated above. Further, it is a surprise that almost all of the customers who gave a 0 rating for inflight wifi service were all satisfied, according to the chart. If the airline can increase this average rating amongst their customers, the number of satisfactory surveys will increase.*

```{r}
#Ease of Online Booking vs Satisfaction
ggplot(airline_train,
       aes(x = Ease.of.Online.booking,
           fill = factor(satisfaction,
           labels = c("Neutral or Dissatisfied", "Satisfied")))) +
  geom_bar(position = "dodge") +
  labs(y = "Number Satisfied", x = "Ease of Online Booking Rating", fill = "satisfaction", title = "Number Satisfied vs Ease of Online Booking")+ theme(plot.title = element_text(hjust = 0.5))

booking_satisfaction <- setNames(aggregate(as.numeric(satisfaction) - 1 ~ Ease.of.Online.booking, data = airline_train, sum), c("Ease of Online Booking Rating", "Total Satisfied"))
booking_satisfaction
```

*The chart above displays the distribution of the ease of online booking rating submitted by customers versus their general satisfaction/dissatisfaction. Similarly to the last chart, as the rating increases, so does the number of satisfied customers. The number of neutral or dissastisfied customers is stable between 2 and 3, reaffirming the mean of the rating. In this chart however, there were customers who were neutral/dissatisfied and satisfied when the rating was 0, slightly opposite of what was in the first chart. If the airline can increase this average rating amongst their customers, the number of satisfactory surveys will increase.*

```{r}
#Gate Location vs Satisfaction
ggplot(airline_train,
       aes(x = Gate.location,
           fill = factor(satisfaction,
           labels = c("Neutral or Dissatisfied", "Satisfied")))) +
  geom_bar(position = "dodge")+
  labs(y = "Number Satisfied", x = "Gate Location Rating", fill = "satisfaction", title = "Number Satisfied vs Gate Location Rating") + theme(plot.title = element_text(hjust = 0.5))

gate_satisfaction <- setNames(aggregate(as.numeric(satisfaction) - 1 ~ Gate.location, data = airline_train, sum), c("Gate Location Rating", "Total Satisfied"))
gate_satisfaction
```

*This chart is much different from the last two for a variety of reasons. First, not one customer answered 0 for the gate location rating, meaning that all were at least slightly satisfied with this service. Subsequently, although the neutral/dissatisfied curve tops out at 3, the number of satisfied customers is fairly stable across all ratings. This could mean that gate location does not play a large role in the satisfaction of a customer. Another piece of evidence that this is true is the 1 and 2 ratings, where the number of neutral/dissatisfied customers and satisfied customers was fairly similar. In all, through this analysis, this metric is not vital for the airline's customers to be satisfied with their experience.*


### Regression 

**Logistic Regression Summary**
```{r}
logit_model <- glm(satisfaction ~ . - Flight.Distance, data = airline_train, family = "binomial")
summary(logit_model)
```
<br />
<br />
**Regression Confusion Matrix and Statistics**
```{r}
prediction <- predict(logit_model, newdata = airline_test, type = "response")
optimal <- optimalCutoff(airline_test$satisfaction, prediction)[1]
binary_predictions <- ifelse(prediction > optimal, 1, 0)

caret::confusionMatrix(as.factor(binary_predictions), as.factor(airline_test$satisfaction))
```

*The logistic regression provides a prediction of satisfaction by using the log odds ratio. The model above achieved an accuracy of 87.3%, sensitivity of 91.4%, and Kappa of 0.74. This shows that the model is helpful in predicting customer satisfaction, along with highlighting the particular areas that impact satisfaction the most. We also optimized the model by using the optimalCutoff function for predicting satisfied (1) or not satisfied (0). While accuracy could be higher, the errors in this model are skewed more towards false negatives than false positives, which is also better because we'd rather not miss dissatisfied customers by thinking they were satisfied when inn reality they were not. Since all variables are significant (besides flight distance), this also means they are all predictive. According to our model, some of the variables that have the highest positive impact on satisfaction are: loyal customers and online boarding, whereas some of the variables that have the most negative impact on satisfaction are: personal travelers and economy/economy plus travelers. Perhaps this means that the airline needs to focus more on these customers and their amenities to boost satisfaction.*
<br />
<br /> 

**Tuned Regression Summary, Confusion Matrix, and Statistics**
```{r}
ctrl <- trainControl(method = "cv", number = 10)

set.seed(300)
logit_model_ctrl <- train(as.factor(satisfaction) ~ ., data = airline_train, method = "glm",
           metric = "Accuracy",
           trControl = ctrl)
summary(logit_model_ctrl)

prediction_ctrl <- predict(logit_model_ctrl, newdata = airline_test, type = "raw")
caret::confusionMatrix(as.factor(prediction_ctrl), as.factor(airline_test$satisfaction))
```

### KNN

**KNN Confusion Matrix and Statistics**
```{r, cache = TRUE}
set.seed(12345)

knn_train <- airline_train_factorized_normalized
knn_test <- airline_test_factorized_normalized
knn_train$satisfaction <- NULL
knn_test$satisfaction <- NULL

# Determine k 
kValue = sqrt(nrow(airline_train_factorized_normalized))

satifaction_test_pred_knn <- knn(train = knn_train, test = knn_test, cl = airline_factorizednormalized_trainlabels$satisfaction, k = 10)

# Confusion Matrix
caret::confusionMatrix(as.factor(satifaction_test_pred_knn), as.factor(airline_factorizednormalized_testlabels$satisfaction))
```

*The confusion matrix shows us that the model is correct 92.89% of the time. The kappa is 0.85, which represents how good the predictions are compared to random guessing. This is quite high, which is an indication of a good model. The p value is sufficiently low, at 0.2.2e-16. Because this figure is below 0.05, the model is significant. Mcnemar’s test p-value is 2.2e-16. Model sensitivity is 0.973 - this is the rate that we correctly identified a non-satisfied customer as a non-satisfied customer. Specificity is 0.873 - this is the rate that we predicted a person was satisfied when they actually were. The model more correctly predicts satisfied customers than non-satisfied customers. Furthermore, this model outperforms the logistic regression.* 

### ANN

**ANN Confusion Matrix and Statistics**
```{r}
#airlineneuralnet1 <- neuralnet(formula = satisfaction ~ ., data = airline_train_factorized_normalized, hidden = 2, stepmax = 10000000000000000)

#save(airlineneuralnet1, file="airline_neural_net1.RData")
load("airline_neural_net1.RData")

model_results <- neuralnet::compute(airlineneuralnet1, airline_test_factorized_normalized)
predicted_y <- model_results$net.result

model_pred <- predict(airlineneuralnet1, newdata = airline_test_factorized_normalized, type = "response")
cutoff <- optimalCutoff(airline_test_factorized_normalized$satisfaction, model_pred)[1]
predicted_ANN_results <- ifelse(model_pred > cutoff, 1, 0) 

caret::confusionMatrix(as.factor(predicted_ANN_results), as.factor(airline_factorizednormalized_testlabels$satisfaction))
```

*The neural net algorithm provides a prediction of satisfaction by using nodes that model the neurons in our brain. To optimize this model, we adjusted the number of hidden nodes and the probability cutoff for a satisfied (1) prediction. We found that adding hidden nodes helped with accuracy. Going to 2 hidden nodes increased the accuracy to about 88%. However, adding any more hidden nodes than 2 proved to be too computationally demanding for the computer to execute. Thereafter, we employed the optimalCutoff function to determine that a cutoff of 44.9% was the optimal value for maximizing accuracy. At its optimal parameters, accuracy is about 88%, sensitivity is about 94%, and Kappa is 0.758. Thus, this model outperforms the logistic regression but underperforms KNN.* 

### Decision Tree 

**Decision Tree Confusion Matrix and Statistics**
```{r}
airline_test$satisfaction <- as.factor(airline_test$satisfaction)
airline_train$satisfaction <- as.factor(airline_train$satisfaction)

airline_decision <- C5.0(satisfaction ~ ., data = airline_train)
airline_decision_pred <- predict(airline_decision, newdata = airline_test)

#CrossTable(airline_test$satisfaction, airline_decision_pred)
airline_decision_pred <- as.factor(airline_decision_pred)

caret::confusionMatrix(airline_decision_pred, airline_test$satisfaction)
```

*Decision Tree models comprise a set of logical decisions. These decisions are represented by decision nodes that indicate decisions to be made based on attributes. This is useful when one needs to be informed on what impacts an outcome in order to influence decision making. We found this model to be very effective when determining customer satisfaction with an accuracy of 96%, sensitivity of 98%, and a Kappa value of 0.9201. Furthermore, the model is skewed towards false negatives over false positives, which is ideal. This makes this model very valuable to us since we can also observe a flowchart of what influences customer satisfaction and also gives us the best metrics.*

### SVM 

**SVM Confusion Matrix and Statistics**
```{r, warning=FALSE}
#building SVM model
#svm_model1 <- ksvm(as.factor(satisfaction) ~., data = airline_train_factorized_normalized, kernel = "rbfdot", scaled = TRUE)

#save(svm_model1, file="svm_model.RData") # saves the result as object to knit and load faster
load("svm_model.RData")

#making predictions
predictions_svm <- predict(svm_model1, airline_test_factorized_normalized)

#evaluating model performance
caret::confusionMatrix(as.factor(predictions_svm), as.factor(airline_test_factorized_normalized$satisfaction))
```

*SVM is a supervised learning method that tries to draw a boundary between two levels of response while maximizing margin and minimizing the distance of the misclassified errors from the best hyperplane (or the separating boundary). There are many different types of boundaries, each type corresponds to a different kernel, which is a function that computes the inner product between our predictors. The most popular kernals are the Radial Basis kernel, Polynomial kernel, and Linear kernel. Upon the inspection of the result from the previous analysis, models that assumes linear solution (such as Logistic Regression) perform worse than models that do not. Therefore, we decided to run the model with the Radial Basis Kernal which is one of the most popular non-linear kernals in SVM.*

*As we can see in the result above, the SVM model achieved an accuracy of 95.11%, sensitivity of 96.65%, and Kappa of 0.9004, which is pretty good and is only outperformed by Decision Tree by a small amount. On top of that, the incorrect prediction skewed more towards false negative, which is good since we want to underestimate the satisfaction of the customer so that we can work harder to improve the our service.*

### Combined Models 

**Combined Model Confusion Matrix and Statistics**
```{r}
combinedTable1 <- data.frame(ANN = as.numeric(predicted_ANN_results), kNN = as.numeric(satifaction_test_pred_knn), logistic = as.numeric(binary_predictions), DT = as.numeric(airline_decision_pred), SVM = as.numeric(predictions_svm))

combinedTable1$kNN <- combinedTable1$kNN - 1
combinedTable1$DT <- combinedTable1$DT - 1
combinedTable1$SVM <- combinedTable1$SVM - 1
combinedTable1$sum <- rowSums(combinedTable1)
combinedTable1$combinedPredictions <- ifelse(combinedTable1$sum >= 3, 1, 0) 

caret::confusionMatrix(as.factor(combinedTable1$combinedPredictions), as.factor(airline_test$satisfaction))
```

*The 1st combined model is based on a simple voting system. If 3 or more models predict satisfied (1), then the combined model predicts satisfied. This leads to an accuracy of 93.89%, sensitivity of 96.77%, and Kappa of 0.8751, making it a relatively good model. It outperforms the logistic regression, KNN, and ANN models. Next, we will look at an ensemble method.*
<br />
<br />

**Stacked Model Confusion Matrix and Statistics**

```{r}
set.seed(123)
combinedTable1$satisfaction <- airline_test_factorized_normalized$satisfaction
test_set <- sample(1:nrow(combinedTable1), 0.2*nrow(combinedTable1))

stacked_train <- combinedTable1[-test_set, ]
stacked_test <- combinedTable1[test_set, ]

stacked_test_labels <- combinedTable1[test_set, "satisfaction"]

stacked_model_tree <- C5.0(as.factor(satisfaction) ~ ANN + kNN + logistic + DT + SVM, data = stacked_train)

stacked_pred <- predict(stacked_model_tree, newdata = stacked_test)

caret::confusionMatrix(as.factor(stacked_pred), as.factor(stacked_test_labels))
```

*The 2nd combined model, the stacked model, improves on the combined model with an accuracy at 96.3%, Kappa value at 0.925, indicating near perfect agreement, and sensitivity at 97.9%. This model runs a decision tree using the data from all the different models' predictions, thereby creating an ensemble method. This model is better than any of the individual models, albeit by a small margin.*

### Conclusion 

Based on our analysis, predicting a satisfied/dissatisfied customer is important. It helps airlines understand not only which types of customers will be most/least satisfied with their service but also the factors that most impact satisfaction across all passengers. These are very important insights for an airline to glean. From the regression model, we have learned that some of the most predictive factors of satisfaction are: loyal customers and online boarding, whereas some of the most predictive factors of dissatisfaction are: personal travelers and economy/economy plus travelers. Thus, the airline should begin to focus on the experience of the economy class traveler first in an effort to boost overall satisfaction. 

The rest of our models are helpful in predicting whether an individual passenger will be satisfied based on a set of characteristics. The best model for this is the stacked model with an accuracy of 96.3%, sensitivity of 97%, and Kappa of 0.925. Nevertheless, the decision tree comes very close with an accuracy of 96%, sensitivity of 98%, and Kappa of 0.9. The advantage of the latter is its greater sensitivity. For an airline, we would still recommend to use the stacked model (which can be further refined) because of its advantage in overall accuracy and Kappa. Nevertheless, if resources or computational power was limited, the decision tree can provide very similar results.   

The high level of accuracy of these models shows us that we can use them comfortably to predict a customer's satisfaction and thereby also decide whether to invest more in the customer (if they are profitable) or less (if they are unprofitable). In the future, with more data, these models can continue to be refined. Nevertheless, we have very strong models we can use already to help the airline improve where it is lacking and invest more in those who are dissatiisfied but profitable customers. 
