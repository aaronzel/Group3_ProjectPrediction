---
title: "Project_3"
author: "Aaron Zelmanov, Muhammad Hafizudeen Mohamad Saman, Nakul Chadha, Kendall Cohen, Michael Geraci"
date: "3/29/2021"
output:
  html_document:
    code_folding: hide
---
## {.tabset}

### Introduction 
```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
library(ggplot2)
library(class)
library(caret)
library(gmodels)
library(InformationValue)
library(C50)
library(neuralnet)
library(InformationValue)
library(dplyr)
library(kernlab)

airline_train <- read.csv("train.csv")
airline_test <- read.csv("test.csv")

airline_train_corr <- airline_train

airline_train$X <- NULL
airline_train$id <- NULL
airline_train$Gender <- as.factor(airline_train$Gender)
airline_train$Customer.Type <- as.factor(airline_train$Customer.Type)
airline_train$Type.of.Travel <- as.factor(airline_train$Type.of.Travel)
airline_train$Class <- as.factor(airline_train$Class)
airline_train$satisfaction <- as.numeric(as.factor(airline_train$satisfaction))-1

airline_test$X <- NULL
airline_test$id <- NULL
airline_test$Gender <- as.factor(airline_test$Gender)
airline_test$Customer.Type <- as.factor(airline_test$Customer.Type)
airline_test$Type.of.Travel <- as.factor(airline_test$Type.of.Travel)
airline_test$Class <- as.factor(airline_test$Class)
airline_test$satisfaction <- as.numeric(as.factor(airline_test$satisfaction))-1

airline_train$Arrival.Delay.in.Minutes[is.na(airline_train$Arrival.Delay.in.Minutes)] <- mean(airline_train$Arrival.Delay.in.Minutes, na.rm = TRUE)
airline_test$Arrival.Delay.in.Minutes[is.na(airline_test$Arrival.Delay.in.Minutes)] <- mean(airline_test$Arrival.Delay.in.Minutes, na.rm = TRUE)
```

**Context:** We are working with the airline dataset which contains various demographics and flight information along with the final satisfaction level.  

**Audience:** The results of our models are useful for airlines in order to optimize their flight experience, lead to maximum satisfaction, and determine which passengers will be satisfied. 

**Key Business Objectives:** What factors are predictive of a satisfied or dissatisfied passenger? How can airlines use this information to improve certain aspects of service? How can airlines predict who to invest more in (dissatisfied passengers)? 

```{r}
#Train and Test sets to use 

#airline_train FOR decision tree, regression
#airline_test FOR decision tree, regression
#airline_train_factorized_normalized FOR KNN, ANN
#airline_test_factorized_normalized FOR KNN, ANN

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) #everything 0 to 1
}

airline_train_factorized<- as.data.frame(model.matrix(~.-1, data = airline_train))
airline_train_factorized_normalized <- as.data.frame(lapply(airline_train_factorized[1:ncol(airline_train_factorized)], normalize))
airline_factorizednormalized_trainlabels <- airline_train_factorized_normalized["satisfaction"]

airline_test_factorized<- as.data.frame(model.matrix(~.-1, data = airline_test))
airline_test_factorized_normalized <- as.data.frame(lapply(airline_test_factorized[1:ncol(airline_test_factorized)], normalize))
airline_factorizednormalized_testlabels <- airline_test_factorized_normalized["satisfaction"]
```

### Data Exploration 

The goal of this analysis is to identify opportunities for which metrics this airline can improve and how that would affect the overall satisfaction of their customers. We want to look at the elements that are the most and least likely to induce a positive or neutral/negative reaction in a customer. This way, we can identify the elements that the airline needs to improve on and where they need to spend the most amount of their resources (time/money).

```{r}
#Correlations with satisfaction 
correlations <- as.data.frame(cor(airline_train[sapply(airline_train, function(x) is.numeric(x))])[19,])
correlations %>% ggplot(aes(x=reorder(rownames(correlations), correlations[,1]), y=correlations[,1])) + 
geom_bar(stat = 'identity') + ggtitle("Correlations with Satisfaction") + labs(x="Variables", y="Correlation") + theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 90))
```

*The correlations graph above shows the correlations between variables in the dataset and satisfaction. Online boarding, in-flight entertainment, and seat comfort seem to be the most strongly correlated with satisfaction. This makes sense because these are some of they key features of a good flight. As a note, satisfaction appears as one of the variables and predictably is 100% correlated with itself. Interestingly, some of the negative aspects of a flight aren't highly negatively correlated: delays, inconvenient departure times, etc* 
<br />
<br />

```{r, warning=FALSE}
#Female = 1, Male = 2
airline_train_corr$Gender <- as.integer(airline_train$Gender)
airline_train_corr$Customer.Type <- as.integer(airline_train$Customer.Type)
airline_train_corr$Type.of.Travel <- as.integer(airline_train$Type.of.Travel)
airline_train_corr$Class <- as.integer(airline_train$Class)
airline_train_corr$satisfaction <- as.integer(airline_train$satisfaction)

airline_train_corr$X <- NULL
airline_train_corr$id <- NULL

GGally::ggcorr(airline_train_corr, nbreaks = 4, palette = "RdGy", label = TRUE, label_size = 2, hjust = 1, label_color = "white") + ggtitle("Correlations") + theme(plot.title = element_text(hjust = 0.5))
```

*The correlations chart above shows us the correlations between all variables, identifying those with strong, weak, and perhaps no correlations*

<br />
<br />
Now, let's take a look at the variables that could have a significant effect on our response.
```{r}
mean_inflight_wifi <- mean(airline_train$Inflight.wifi.service)
mean_departure_arrival <- mean(airline_train$Departure.Arrival.time.convenient)
mean_ease <- mean(airline_train$Ease.of.Online.booking)
mean_gate <- mean(airline_train$Gate.location)
mean_food_drink <- mean(airline_train$Food.and.drink)
mean_online_board <- mean(airline_train$Online.boarding)
mean_seat <- mean(airline_train$Seat.comfort)
mean_inflight_entertain <- mean(airline_train$Inflight.entertainment)
mean_onboard_service <- mean(airline_train$On.board.service)
mean_leg_room <- mean(airline_train$Leg.room.service)
mean_baggage <- mean(airline_train$Baggage.handling)
mean_checkin <- mean(airline_train$Checkin.service)
mean_inflight_service <- mean(airline_train$Inflight.service)
mean_cleanliness <- mean(airline_train$Cleanliness)
mean_df <- data.frame(mean_inflight_wifi, mean_departure_arrival, mean_ease, mean_gate, mean_food_drink, mean_online_board, mean_seat, mean_inflight_entertain, mean_onboard_service, mean_leg_room, mean_baggage, mean_checkin, mean_inflight_service, mean_cleanliness)

colnames(mean_df) <- c("InFlight Wifi Service", "Departure Arrival Time Convenient", "Ease of Online Booking", "Gate Location", "Food & Drink", "Online Boarding", "Seat Comfort", "Inflight Entertainment", "On-board Service", "Leg Room Service", "Baggage Handling", "Check-in Service", "Inflight Service", "Cleanliness")

mean_df
```

*After calculating the mean customer ratings for 14 different variables (services, timing, locations, accessibility, etc), three variables automatically stand out as those that the airline needs to focus on: Inflight Wifi Service, Ease of Online Booking, and Gate Location. If it could improve on these three, the more likely more customers will be satisfied with their experiences.*
<br />
<br />
Let's dive deeper into these three variables and see their relationship with satisfaction.

```{r}
wifi_service_plot <- ggplot(data=airline_train, aes(x=Inflight.wifi.service, y=satisfaction)) + geom_jitter() + xlab("Inflight Wifi Service") + ylab("Satisfaction") + ggtitle("Inflight Wifi Service vs Satisfaction") + theme(plot.title = element_text(hjust = 0.5))
wifi_service_plot
```

```{r}
GGally::ggpairs(
  airline_train, 
  columns = c("Inflight.wifi.service", "Ease.of.Online.booking", "Gate.location"), 
  columnLabels = c("Inflight Wifi Service", "Ease of Online Booking", "Gate Location"),
  lower = list(
    continuous = "smooth"
  ),
  diag = list(
    continuous = "smooth"
  ),
  upper = list(
    continuous = "smooth"
  )
)
```


**ADD OTHER 2 GRAPHS HERE**


### Regression 

**Logistic Regression Summaries**
```{r}
logit_model1 <- glm(satisfaction ~., data = airline_train, family = "binomial")
summary(logit_model1)

#logit_model2 <- step (logit_model1)
#summary(logit_model2)

logit_model3 <- glm(satisfaction ~ . - Flight.Distance, data = airline_train, family = "binomial")
summary(logit_model3)
```
<br />
<br />
**Regression Confusion Matrix and Statistics**
```{r}
prediction <- predict(logit_model3, newdata = airline_test, type = "response")
optimal <- optimalCutoff(airline_test$satisfaction, prediction)[1]
binary_predictions <- ifelse(prediction > optimal, 1, 0)

caret::confusionMatrix(as.factor(binary_predictions), as.factor(airline_test$satisfaction))
```

The logistic regression provides a prediction of satisfaction by using the log odds ratio. The model above achieved an accuracy of 87.3%, sensitivity of 91.4%, and Kappa of 0.74. This shows that the model is helpful in predicting customer satisfaction, along with highlighting the particular areas that impact satisfaction the most. We also optimized the model by using the optimalCutoff function for predicting satisfied (1) or not satisfied (0). While accuracy could be higher, the errors in this model are skewed more towards false negatives than false positives, which is also better because we'd rather not miss dissatisfied customers by thinking they were satisfied when inn reality they were not. Since all variables are significant (besides flight distance), this also means they are all predictive. According to our model, some of the variables that have the highest positive impact on satisfaction are: loyal customers and online boarding, whereas some of the variables that have the most negative impact on satisfaction are: personal travelers and economy/economy plus travelers. Perhaps this means that the airline needs to focus more on these customers and their amenities to boost satisfaction.

### KNN

**KNN Confusion Matrix and Statistics**
```{r, cache = TRUE}
set.seed(12345)

knn_train <- airline_train_factorized_normalized
knn_test <- airline_test_factorized_normalized
knn_train$satisfaction <- NULL
knn_test$satisfaction <- NULL

# Determine k 
kValue = sqrt(nrow(airline_train_factorized_normalized))

satifaction_test_pred_knn <- knn(train = knn_train, test = knn_test, cl = airline_factorizednormalized_trainlabels$satisfaction, k = 10)

# Confusion Matrix
caret::confusionMatrix(as.factor(satifaction_test_pred_knn), as.factor(airline_factorizednormalized_testlabels$satisfaction))
```

**ADD MODEL TUNING HERE?**

### ANN

**ANN Confusion Matrix and Statistics**
```{r, cache = TRUE}
airlineneuralnet1 <- neuralnet(formula = satisfaction ~ ., data = airline_train_factorized_normalized, hidden = 2, stepmax = 10000000000000000)

model_results <- neuralnet::compute(airlineneuralnet1, airline_test_factorized_normalized)
predicted_y <- model_results$net.result

model_pred <- predict(airlineneuralnet1, newdata = airline_test_factorized_normalized, type = "response")
cutoff <- optimalCutoff(airline_test_factorized_normalized$satisfaction, model_pred)[1]
predicted_ANN_results <- ifelse(model_pred > cutoff, 1, 0) 

caret::confusionMatrix(as.factor(predicted_ANN_results), as.factor(airline_factorizednormalized_testlabels$satisfaction))
```

The neural net algorithm provides a prediction of satisfaction by using nodes that model the neurons in our brain. To optimize this model, we adjusted the number of hidden nodes and the probability cutoff for a satisfied (1) prediction. We found that adding hidden nodes helped with accuracy. Going to 2 hidden nodes increased the accuracy to 91%. However, adding any more hidden nodes than 2 proved to be too computationally demanding for the computer to execute. Thereafter, we employed the optimalCutoff function to determine that a cutoff of 41.9% was the optimal value for maximizing accuracy. At this cutoff, sensitivity remains high too. This model is also advantageous in its distribution of errors as it is skewed towards false negatives over false positives. While this model performs well, it is more computationally demannding thann KNN, despite providing similar results. 

### Decision Tree 

**Decision Tree Confusion Matrix and Statistics**
```{r}
airline_test$satisfaction <- as.factor(airline_test$satisfaction)
airline_train$satisfaction <- as.factor(airline_train$satisfaction)

airline_decision <- C5.0(satisfaction ~ ., data = airline_train)
airline_decision_pred <- predict(airline_decision, newdata = airline_test)

#CrossTable(airline_test$satisfaction, airline_decision_pred)
airline_decision_pred <- as.factor(airline_decision_pred)

caret::confusionMatrix(airline_decision_pred, airline_test$satisfaction)
```

### SVM 
SVM is a supervised learning method that tries to draw a boundary between two levels of response while maximizing margin and minimizing the distance of the misclassified errors from the best hyperplane (or the separating boundary). There are many different types of boundaries, each type corresponds to a different kernel, which is a function that computes the inner product between our predictors. The most popular kernals are the Radial Basis kernel, Polynomial kernel, and Linear kernel. However, non-linear kernals are computationally expensive to run, so we are going to run only the linear kernal. Note that the linear kernal corresponds to the parameter option "vanilladot" in kernlab library.

**SVM Confusion Matrix and Statistics**
```{r, warning=FALSE}
#building SVM model
#svm_model1 <- ksvm(as.factor(satisfaction) ~., data = airline_train_factorized_normalized2, kernel = "vanilladot", scaled = TRUE)

#save(svm_model1, file="svm_model.RData") # saves the result as object to knit and load faster
load("svm_model.RData")

#making predictions
predictions_svm <- predict(svm_model1, airline_test_factorized_normalized)

#evaluating model performance
caret::confusionMatrix(as.factor(predictions_svm), as.factor(airline_test_factorized_normalized$satisfaction))
```

Because running SVM model in such a huge dataset consumes a lot of computational resources, we decided to run it only once and save the result in a file. This way, knitting the file would not take too much time because we only need to load the result instead of running the model again.

As we can see in the result above, the SVM model achieved an accuracy of 87.3%, sensitivity of 92.3%, and Kappa of 0.741, which is reasonable, but performs worse in comparison to Decision Tree model or ANN. However, the incorrect prediction skewed more towards false negative, which is good since we want to underestimate the satisfaction of the customer so that we can work harder to improve the our service.

### Combined Models 

**Combined Model Confusion Matrix and Statistics**
```{r}
combinedTable1 <- data.frame(ANN = as.numeric(predicted_ANN_results), kNN = as.numeric(satifaction_test_pred_knn), logistic = as.numeric(binary_predictions), DT = as.numeric(airline_decision_pred), SVM = as.numeric(predictions_svm))

combinedTable1$sum <- rowSums(combinedTable1)
combinedTable1$combinedPredictions <- ifelse(combinedTable1$sum >= 4, 1, 0) 

caret::confusionMatrix(as.factor(combinedTable1$combinedPredictions), as.factor(airline_test$satisfaction))
```

**Stacked Model Confusion Matrix and Statistics**
```{r}

```


### Conclusion 
