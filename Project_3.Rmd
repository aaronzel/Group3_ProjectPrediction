---
title: "Project_3"
author: "Aaron Zelmanov"
date: "3/29/2021"
output:
  html_document:
    code_folding: hide
---


### Data Exploration 

The goal of this analysis is to identify opportunities for which metrics this airline can improve and how that would affect the overall satisfaction of their customers. We want to look at the elements that are the most and least likely to induce a positive or neutral/negative reaction in a customer. This way, we can identify the elements that the airline needs to improve on and where they need to spend the most amount of their resources (time/money).

```{r}
#Correlations with satisfaction 
#correlations <- as.data.frame(cor(airline_train[sapply(airline_train, function(x) is.numeric(x))])[19,])
#correlations %>% ggplot(aes(x=reorder(rownames(correlations), correlations[,1]), y=correlations[,1])) + 
#geom_bar(stat = 'identity') + ggtitle("Correlations with Satisfaction") + labs(x="Variables", y="Correlation") + theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 90))

```

Now, let's take a look at the variables that could have a significant effect on our response.

```{r}
ggplot(data = airline_train_factorized, aes(x = Inflight.wifi.service, y = satisfaction, colour = satisfaction)) + geom_jitter() + xlab("Inflight Wifi Service") + ylab("Satisfaction") + ggtitle("Inflight Wifi Service vs Satisfaction") + theme(plot.title = element_text(hjust = 0.5))
```

### Regression 

```{r}
logit_model1 <- glm(satisfaction ~., data = airline_train, family = "binomial")
summary(logit_model1)

prediction <- predict(logit_model1, newdata = airline_test, type = "response")

#optimal <- optimalCutoff(airline_test$satisfaction, prediction)[1]

#binary_predictions <- ifelse(prediction > optimal, 1, 0)

#airline_test_labels <- airline_test[airline_test, "satisfaction"]

#CrossTable(x = airline_test$satisfaction, y = binary_predictions, prop.chisq = FALSE)
```

### KNN

```{r}

```


### ANN

```{r cache = TRUE}
airlineneuralnet1 <- neuralnet(formula = satisfaction ~ ., data = airline_train_factorized_normalized, hidden = 2)

model_results <- compute(airlineneuralnet1, airline_test_factorized_normalized)
predicted_y <- model_results$net.result
summary(predicted_y)

model_pred <- predict(airlineneuralnet1, newdata = airline_test_factorized_normalized, type = "response")
cutoff <- optimalCutoff(airline_test_factorized_normalized$satisfaction, model_pred)[1]
predicted_ANN_results <- ifelse(model_pred > cutoff, 1, 0) 

caret::confusionMatrix(as.factor(predicted_ANN_results), as.factor(airline_factorizednormalized_testlabels$satisfaction)) #WHY $ HERE??
```

The neural net algorithm provides a prediction of satisfaction by using nodes that model the neurons in our brain. To optimize this model, I adjusted the number of hidden nodes and the probability cutoff for a yes (1) prediction. I found that adding hidden nodes helped with accuracy. Going to 2 hidden nodes increased the accuracy to 91%. However, adding any more hidden nodes than 2 proved to be too computationally demanding for the computer to execute. Thereafter, I employed the optimalCutoff function to determine that a cutoff of 41.9% was the optimal value for maximizing accuracy. At this cutoff, sensitivity remains high too. 

### Decision Tree 

```{r}
airline_test$satisfaction <- as.factor(airline_test$satisfaction)
airline_train$satisfaction <- as.factor(airline_train$satisfaction)

airline_decision <- C5.0(satisfaction ~ ., data = airline_train)
airline_decision_pred <- predict(airline_decision, newdata = airline_test)

CrossTable(airline_test$satisfaction, airline_decision_pred)
airline_decision_pred <- as.factor(airline_decision_pred)
caret::confusionMatrix(airline_decision_pred, airline_test$satisfaction)
```

### SVM 

```{r}

```

### Combined Model 

```{r}

```


### Conclusion 
